---
title: "test lsm"
author: "Meghan Bowen"
date: "6/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Load packages

```{r load_packages}

library(tidyverse) 
library(raster) ##load and manipulate rasters
library(sf) ##load shapefiles
library(sp) ##spatial objects
library(spatstat) ##work with shapefiles
library(tmap) ##map rasters + shapefiles
library(rgdal) ##for projections and coord systems

library(gfcanalysis) ##package specifically for Hansen Forestry Data!
library(landscapetools) ##for landscape plotting/viz?
library(landscapemetrics) ##R equivalent to FRAGSTATS

```

## Part 1. Load municipalities

```{r load_shps}

muni_shp <- read_sf(dsn = 'municipality_shapefiles', layer = "Amazon_Municipios")

##filtering to select Altamira (largest municipality in Amazon? idk)
altamira_shp <- muni_shp %>% 
  dplyr::filter(nome == "Altamira")

```


## Part 2. Load forestry rasters 

```{r download_forestdata}

##need to convert the municipality .shp to a "SpatialDataFrame" so gfcanalysis can grab the forestry tiles online
spd <- sf::as_Spatial(st_geometry(muni_shp),
                      IDs = as.character(1:nrow(muni_shp)))

muni_df <- as.data.frame(muni_shp)

muni_spd <- sp::SpatialPolygonsDataFrame(spd, data = muni_df)

#find the # of tiles needed. 
tiles <- calc_gfc_tiles(aoi = muni_spd)
tiles


##CODE FOR ALL TILES

```

```{r download_forest_altamira}

##need to convert the municipality .shp to a "SpatialDataFrame" so gfcanalysis can grab the forestry tiles online
spd_alta <- sf::as_Spatial(st_geometry(altamira_shp),
                      IDs = as.character(1:nrow(altamira_shp)))

alta_df <- as.data.frame(altamira_shp)

alta_spd <- sp::SpatialPolygonsDataFrame(spd_alta, data = alta_df)

#find the # of tiles needed. 
tiles <- calc_gfc_tiles(aoi = alta_spd)
tiles

##DOWNLOAD ALTAMIRA TILE
download_tiles(tiles, output_folder = ".", dataset = "GFC-2018-v1.6",images = c("treecover2000", "lossyear", "gain"))

```


```{r altamira_subsets}

##load the Altamira tile
alta_lossyear <- raster("Hansen_GFC-2018-v1.6_lossyear_00N_060W.tif") 

##clip the tile to the Altamira province
alta_clip <- crop(alta_lossyear, extent(alta_spd))

##filter by each year. Includes all previous years (so 2002 includes 1 AND 2 layers)
##Can I MAKE THIS CLEANER? SAPPLY/LAPPLY?

##write your own function?


alta_2001 <- alta_clip %in% 1
alta_2002 <- alta_clip %in% 1:2
alta_2003 <- alta_clip %in% 1:3


```

```{r altamira_lsm}

##patch metrics for Altamira only

lsm_abb <- lsm_abbreviations_names

##Patch Area for Each Level (2001, 2001-2002, etc)
##Directions = 8 meanest 8 directions of nearest neighbor calculations
p_area01 <- lsm_p_area(alta_2001, 
                       directions = 8)
p_area02 <- lsm_p_area(alta_2002, 
                       directions = 8)
p_area03 <- lsm_p_area(alta_2003, 
                       directions = 8)

##extract lsm --> use to plot patches?? look into more
##with extract_lsm can specific metrics. 

```


##notes 

- write output to a .csv for the whole amazon. easy output for csv for metrics
- each row is a municipality. for landscape level outputs
- patch metrics would be an average across the municipality
- each column has different metrics (edge length)
- codigo_ibg == is like a county code. would be more useful to link up with malaria reporting data. maybe grab it and merge it with the landscapemetric data
- once all of the years are separated out do the landscape level metric calculations 
- four vs. eight neighbor differences? look @ papers in fragstats
- run four and run eight, check for significant differences in outputs
