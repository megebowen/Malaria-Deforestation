---
title: "test lsm"
author: "Meghan Bowen"
date: "6/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Load packages

```{r load_packages}

library(tidyverse) 
library(raster) ##load and manipulate rasters
library(sf) ##load shapefiles
library(sp) ##spatial objects
library(spatstat) ##work with shapefiles
library(tmap) ##map rasters + shapefiles
library(rgdal) ##for projections and coord systems

library(gfcanalysis) ##package specifically for Hansen Forestry Data!
library(landscapetools) ##for landscape plotting/viz?
library(landscapemetrics) ##R equivalent to FRAGSTATS

```

## Part 1. Load municipalities

```{r load_shps}

muni_shp <- read_sf(dsn = 'municipality_shapefiles', layer = "Amazon_Municipios")

##filtering to select Altamira (largest municipality in Amazon? idk)
altamira_shp <- muni_shp %>% 
  dplyr::filter(nome == "Altamira")

```


## Part 2. Load forestry rasters 

```{r download_forestdata}

##need to convert the municipality .shp to a "SpatialDataFrame" so gfcanalysis can grab the forestry tiles online
spd <- sf::as_Spatial(st_geometry(muni_shp),
                      IDs = as.character(1:nrow(muni_shp)))

muni_df <- as.data.frame(muni_shp)

muni_spd <- sp::SpatialPolygonsDataFrame(spd, data = muni_df)

#find the # of tiles needed. 
tiles <- calc_gfc_tiles(aoi = muni_spd)
tiles


##CODE FOR ALL TILES

#1. Download

#2. Mosaic all rasters together

#3. Extract fxn to extract tiles BY the muni_spd
##extract_muni <- extract(XXMOSAIC, muni_spd)

```

```{r download_forest_altamira}

##need to convert the municipality .shp to a "SpatialDataFrame" so gfcanalysis can grab the forestry tiles online
spd_alta <- sf::as_Spatial(st_geometry(altamira_shp),
                      IDs = as.character(1:nrow(altamira_shp)))

alta_df <- as.data.frame(altamira_shp)

alta_spd <- sp::SpatialPolygonsDataFrame(spd_alta, data = alta_df)

#find the # of tiles needed. 
tiles <- calc_gfc_tiles(aoi = alta_spd)
tiles

##DOWNLOAD ALTAMIRA TILE
download_tiles(tiles, output_folder = ".", dataset = "GFC-2018-v1.6",images = c("treecover2000", "lossyear", "gain"))

##extract
alta_data <- extract_gfc(alta_spd, data_folder = "/Users/meghanbowen/Desktop/Bren/Macdonald_Lab/github/Malaria-Deforestation/tile_outputs", filename = "/Users/meghanbowen/Desktop/Bren/Macdonald_Lab/github/Malaria-Deforestation/GFC_studyArea.tif")

```


```{r altamira_subsets}

##load the Altamira tile.
alta_lossyear <- raster("Hansen_GFC-2018-v1.6_lossyear_00N_060W.tif")

##crop extent to Altamira
alta_crop <- crop(alta_lossyear, extent(altamira_shp))

##mask extent to Altamira
alta_mask <- mask(alta_crop, altamira_shp)

alta_values <- getValues(alta_mask)

#ERROR: no loop for break/next, jumping to top level 
###alta_extract <- extract(x = alta_lossyear, y = alta_spd, df = TRUE)

##filter by each year. Includes all previous years (so 2002 includes 1 AND 2 layers)

#output
year_rast_list <- list()

#function
for (i in 1:18){
  year_rast_list[[i]] <- alta_mask %in% 1:i
}

#return


alta_2001 <- alta_mask %in% 1
alta_2002 <- alta_mask %in% 1:2
alta_2003 <- alta_mask %in% 1:3

##COMPARE
par(mfrow=c(1,2))
plot(alta_2003)
plot(altamira_shp$geometry, add=T)
plot(year_rast_list[[3]])
plot(altamira_shp$geometry, add=T)

```

##Function 1: Separate out by each municipality

- basically need to create 807 outputs, one for each unique municipality. These are the landscapes to run lsm on

```{r filter_allmuni}

##function #1: filter all by landscape (municipality)
#load all municipality shapefile
muni_shp <- read_sf(dsn = 'municipality_shapefiles', layer = "Amazon_Municipios")

##smaller size if split by muni_shp
####ERROR: MUNI SPLIT BY NOME ONLY RETURNS A LIST WITH 801!
#muni_split <- split(muni_shp, muni_shp$nome)

##OK: CODIGO SPLIT BY CODIGO_IBG RETURNS ALL 807!!!
codigo_split <- split(muni_shp, muni_shp$codigo_ibg)

##function 2: get raster data for every polygon
total_poly <- length(muni_spd@polygons) #note this will only work for spd

#output
poly_rast_list <- list()

#function DO NOT RUN
for (nome in muni_spd@data) {
  ##crop to extent of EACH polygon in muni SpatialDataFrame (i)
  municrop <- crop(alta_lossyear, extent(muni_spd$nome)) ##need to change to all lossyear raster
  
  ##mask with above cropped extent (i) for EACH polygon in muni SpatialDataFrame (i)
  munimask <- mask(municrop, muni_spd$nome)##test if this works
}

#return

##test this on altamira
#load the Altamira tile. 
alta_lossyear <- raster("Hansen_GFC-2018-v1.6_lossyear_00N_060W.tif")
alta_crop <- crop(alta_lossyear, extent(altamira_shp))
alta_mask <- mask(alta_crop, altamira_shp)

#clip the tile to the Altamira province
alta_crop2 <- crop(alta_lossyear, extent(muni_split$Altamira))
alta_mask2 <- mask(alta_crop2, muni_split$Altamira) ##alta_mask2 %in% 1 is the same as alta_2001 above! hooray.

```


##Function 2: Separate out by each year (cell value?)
- 807 (# of munis) * 18 (# of years) = 14,526 unique landscapes (and 14,526 outputs?!)

##Function 3: Run LSM for each municipality (landscape) for each year (cell value)

##Function 4: Combine ^^ results into one df

```{r altamira_lsm}

##literal landscape metrics for Altamira only

lsm_abb <- lsm_abbreviations_names

##Landscape Total Edge for Each Level (2001, 2001-2002, etc)
##DOES lsm_l_xx not let you choose between 4 and 8 neighbors?! what is the default?
l_edge01 <- lsm_l_te(alta_2001) %>% 
  dplyr::mutate(year="2001")
l_edge02 <- lsm_l_te(alta_2002) %>% 
  dplyr::mutate(year="2002")
l_edge03 <- lsm_l_te(alta_2003) %>% 
  dplyr::mutate(year="2003")

##for loop to run all years for all rasters

alta_lsm_list <- list()

#function
for (i in 1:18){
  alta_lsm_list[[i]] <- lsm_l_te(year_rast_list[[i]])
}

#return
```


```{r combination}
##combine rows for each municipality for each year
##only keep columns "year", "TotalEdge" [OR WHATEVER ADDITIONAL METRIC NAMES] "codigo_ibg" ??
alta_bind <- rbind(l_edge01, l_edge02, l_edge03) %>% 
  dplyr::mutate(codigo_ibg= "1500602") %>% 
  dplyr::rename(TotalEdge = value)

##combine altamira/muni with muni_shp. 
##FYI THESE VALUES ARE DIFFERENT FOR ALTA_MASK THAN ALTA_CROP!!
alta_geo <- full_join(alta_bind, altamira_shp, by = "codigo_ibg")

```


##notes 6.18.19

- write output to a .csv for the whole amazon. easy output for csv for metrics
- each row is a municipality. for landscape level outputs
- patch metrics would be an average across the municipality
- each column has different metrics (edge length)
- codigo_ibg == is like a county code. would be more useful to link up with malaria reporting data. maybe grab it and merge it with the landscapemetric data
- once all of the years are separated out do the landscape level metric calculations 
- four vs. eight neighbor differences? look @ papers in fragstats. run four and run eight, check for significant differences in outputs

###Example function

function_name <- function(arg1, arg2, arg 3=4) {
                    newvar <- (arg1)^2 + (1/arg2)
                    return(newvar/arg3)
}

##notes 6.23.19

- MAKE INTO A FINAL SCRIPT, WILL BE FASTER 
- ok quick question. since the raster values (1 for now) are technically lost forest, should the value (1 for now) be reversed to represent still intact forest?? **so, if a value of 0 is intact forest and 1 is forest loss in X year, should these be flipped so that 1 is intact forest and 0 is forest loss in X year??**
- once all of the years are separated out do the landscape level metric calculations --> **FOR EACH YEAR?**
- four vs. eight neighbor differences? look @ papers in fragstats **might not be relevant for landscape level calclations**

##notes 6.25.19

- is there an argument to ignore the border of the municipality to calculate metrics? what is the total edge calculation giving us, and is it ignoring the borders in calculations?
- NEED TO DO RASTER CALCULATIONS to get forest that remains. 1 is forest remains, 0 is not forest. forest in 2001 == forest in 2001- forest in 2000. **do this after the code is good**
- if bored, look at other metrics for landscapes and the raster calculations




